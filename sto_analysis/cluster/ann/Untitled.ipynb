{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load get_ann_y_v1.py\n",
    "# %load stock_in_minut.py\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "#from numpy._distributor_init import NUMPY_MKL\n",
    "from sklearn.cluster import KMeans\n",
    "market='shenzhen'\n",
    "from load_path import *\n",
    "from package1.download_data.download_daily_price_volume_v2 import *\n",
    "from package1.path import *\n",
    "from data_in_minute import *\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "stock_path=os.path.join(stock_index_path,market)\n",
    "sto2=os.listdir(stock_path)\n",
    "#print sto2\n",
    "date1=\"2017-09-28\"\n",
    "stk_num=sto2[0][0:6]\n",
    "data_file=\"g:/stock/data/daily_price_volume/shenzhen/%s/%s_%s.csv\" % (stk_num,stk_num,date1)\n",
    "\n",
    "## this function get the dataframe in minute\n",
    "def get_data(data_file):\n",
    "    #data_file=\"g:/stock/data/daily_price_volume/shenzhen/%s/%s_%s.csv\" % (stk_num,stk_num,date1)\n",
    "    df_in_minut=data_in_minut(data_file,3)\n",
    "    df_in_minut1=df_in_minut.values.T.tolist()\n",
    "    return df_in_minut1[0]\n",
    "\n",
    "def get_data2(df_in,stock_in,match1):\n",
    "    data_norm=[]\n",
    "    data_raw=[]\n",
    "    stock_index_match=[]\n",
    "    for m1 in match1:\n",
    "        data_norm.append((df_in[m1]-np.mean(df_in[m1]))/np.mean(df_in[m1])) ### normarlized the data\n",
    "        data_raw.append(df_in[m1])\n",
    "        stock_index_match.append(stock_in[m1])\n",
    "    data_norm=np.array(data_norm)\n",
    "    return [data_raw,data_norm,stock_index_match]\n",
    "\n",
    "def dele_not_match_transform(len1,df_in1,stock_in1,len2,df_in2,stock_in2):\n",
    "    cnt=Counter(len1)  # count the most common elements\n",
    "    # print cnt\n",
    "    most_common=cnt.most_common(1)[0][0]  ### find most common length of every data\n",
    "    matches1= zip(*[(i,j) for (i,j) in enumerate(len1) if j ==most_common])  ## find the index which match the most common\n",
    "    matches2= zip(*[(i,j) for (i,j) in enumerate(len2) if j ==most_common])  ## find the index which match the most common\n",
    "    #print matches\n",
    "    #print df_in[0]\n",
    "    match1=list((set(matches1[0]) & set(matches2[0])))\n",
    "    data_raw1,data_norm1,stock_index_match1=get_data2(df_in1,stock_in1,match1)\n",
    "    data_raw2,data_norm2,stock_index_match2=get_data2(df_in2,stock_in2,match1)\n",
    "    return [data_raw1,data_norm1,stock_index_match1,data_raw2,data_norm2,stock_index_match2]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n",
      "fuck\n"
     ]
    }
   ],
   "source": [
    "date1=\"2017-09-21\"\n",
    "date2=\"2017-09-22\"\n",
    "df_in1,df_in2=[],[]\n",
    "stock_in1,stock_in2=[],[]\n",
    "len1,len2=[],[]\n",
    "for i in range(0,1000):\n",
    "    j=sto2[i]\n",
    "    stk_num=j[0:6]\n",
    "    data_file1=\"g:/stock/data/daily_price_volume/shenzhen/%s/%s_%s.csv\" % (stk_num,stk_num,date1)\n",
    "    data_file2=\"g:/stock/data/daily_price_volume/shenzhen/%s/%s_%s.csv\" % (stk_num,stk_num,date2)\n",
    "    try:\n",
    "        df_in_minut1=get_data(data_file1)\n",
    "        df_in_minut2=get_data(data_file2)\n",
    "        if len(df_in_minut1)>0 and len(df_in_minut2)>0:   ## if both day have data we keep the data frame\n",
    "            df_in1.append(df_in_minut1)\n",
    "            stock_in1.append(stk_num)\n",
    "            len1.append(len(df_in_minut1))\n",
    "            df_in2.append(df_in_minut2)\n",
    "            stock_in2.append(stk_num)\n",
    "            len2.append(len(df_in_minut2))\n",
    "    except:\n",
    "        print 'fuck'\n",
    "data_raw1,data_norm1,stock_index_match1,data_raw2,data_norm2,stock_index_match2=dele_not_match_transform(len1,df_in1,stock_in1,len2,df_in2,stock_in2)\n",
    "X=data_raw1\n",
    "today_max=[np.max(x) for x in data_raw2]\n",
    "yest_mean=[np.max(x) for x in data_raw1]\n",
    "diff=map(lambda(a,b):a-b,zip(today_max,yest_mean))\n",
    "\n",
    "diff_ch=[]\n",
    "for diff1 in diff:\n",
    "    if diff1>0:\n",
    "        diff_ch.append(1)\n",
    "    else:\n",
    "        diff_ch.append(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n",
    "len_ann=len(X)\n",
    "samp=random.sample(xrange(0,len_ann),int(len_ann*0.8))\n",
    "pred=[i for i in xrange(0,len_ann) if i not in samp]\n",
    "y=diff_ch\n",
    "x_samp=[]\n",
    "y_samp=[]\n",
    "for samp1 in samp:\n",
    "    x_samp.append(X[samp1])\n",
    "    y_samp.append(y[samp1])\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(60,10), random_state=1)\n",
    "clf.fit(x_samp, y_samp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corret percentage:  0.5679\n"
     ]
    }
   ],
   "source": [
    "totl=0\n",
    "correct=0\n",
    "for i in pred:\n",
    "    dif=clf.predict([X[i]])-y[i]\n",
    "    totl+=1\n",
    "    if dif==0:\n",
    "        correct+=1\n",
    "    #print 'predict: ',clf.predict([X[i]]), 'observe:', y[i]\n",
    "print 'corret percentage: ',round(float(correct)/float(totl),4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
